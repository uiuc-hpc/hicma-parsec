extern "C" %{
/**
 * @copyright (c) 2018 King Abdullah University of Science and Technology (KAUST).
 *                     All rights reserved.
 **/
#include "common.h"
#include "hicma_hcore.h"
#include "hicma.h"
#include "ka_counts.h"
#include <starsh.h>

#include "parsec/data_dist/matrix/matrix.h"
#include "parsec/private_mempool.h"
#include "parsec/runtime.h"
#include "parsec/data_internal.h"
#include "parsec/data_dist/matrix/sym_two_dim_rectangle_cyclic_band.h"
#include <string.h>

#include "hicma_parsec_internal.h"

/* BODY type */
#define PARSEC_HAVE_RECURSIVE 1

/* Used for operation count */
extern unsigned long *op_band, *op_offband, *op_path, *op_offpath;

#if defined(PARSEC_HAVE_RECURSIVE)
#include "parsec/data_dist/matrix/subtile.h"
#include "parsec/recursive.h"
#endif

/*
 * Priorities used in this jdf:
 *      - potrf_dpotrf(k)    : (MT-k)**3
 *      - potrf_dsyrk(k,m)   : (MT-m)**3 + 3 * (m - k)
 *      - potrf_dtrsm(m,k)   : (MT-m)**3 + 3 * (m - k) * (2 * MT - k - m - 1)
 *      - potrf_dgemm(m,n,k) : (MT-m)**3 + 3 * (m - n) * (2 * MT - m - n - 1) + 6 * (m - k)
 *
 * So max priority is:
 *      (MT - PRI_CHANGE)**3 + 3 * MT * (2 * MT - PRI_CHANGE - 1) + 6 * MT  < (MT**3 + 6 MT**2 + 3 MT)
 *
 * WARNING: If mt is greater than 1200, we might get integer overflow.
 */
#ifdef printlog
#undef printlog
#endif
#include <stdarg.h>
static void nullfunc(const char* fmt, ...){}
#define printlog nullfunc
#define LOG_OPCOUNT(cnt, i, j) \
    do{\
        int myrank; \
        MPI_Comm_rank(MPI_COMM_WORLD, &myrank);\
        int nth = es->virtual_process->nb_cores;\
        if(0)printf("%s rank:%d th_id:%d nthreads per node:%d\n", __func__, myrank, es->th_id, nth);\
        int myid = es->th_id;\
        opcounters[myrank*nth+myid] += cnt;  \
        tileopcounters[i*descA->nt+j] += cnt; \
    }while(0);

static inline int define_k_pre(parsec_tiled_matrix_dc_t *descRG, int m, int n, int k) { 
    if( descRG->super.myrank == sym_twoDBC_band_rank_of(&descRG->super, m, n) ) {
	return ((int *)((descRG->super.data_of(&descRG->super, m, n))->device_copies[0]->device_private))[k];

    } else
        return -1;
}

static inline int define_k_next(parsec_tiled_matrix_dc_t *descRG, int m, int n, int k) {
    if( descRG->super.myrank == sym_twoDBC_band_rank_of(&descRG->super, m, n) ) {
        return ((int *)((descRG->super.data_of(&descRG->super, m, n))->device_copies[0]->device_private))[n+k];

    } else
        return -1;
}

#if defined(PARSEC_HAVE_CUDA)
/* Lookup GPU workspace */
static parsec_potrf_stream_workspace_t lookup_gpu_workspace( parsec_device_cuda_module_t *gpu_device,
                                                           parsec_gpu_exec_stream_t *gpu_stream,
                                                           parsec_potrf_workspace_t *ws ) {
    int i, j;

    /* Look for device */
    for(i = 0; i < (int)parsec_nb_devices; i++) {
        parsec_device_module_t *device = parsec_mca_device_get(i);
        if( NULL == device ) continue;
        if( device->type != PARSEC_DEV_CUDA ) continue;
        parsec_device_cuda_module_t *gpu_device_compare = (parsec_device_cuda_module_t*)device;

        if(gpu_device->cuda_index == gpu_device_compare->cuda_index)
            break;
    }

    /* Look for stream; 0, h2d; 1 d2h*/
    for(j = 2; j < gpu_device->max_exec_streams; j++) {
        char *name_compare;
        asprintf(&name_compare, "cuda(%d)", j);

        if( !strcmp(name_compare, gpu_stream->name) )
            break;
    }

    assert( i < (int)parsec_nb_devices );
    assert( j > 1 );
    assert( j < gpu_device->max_exec_streams );

    return ws->gpu_workspace[i].stream_workspace[j];
}
#endif


%}

/* Globals
 */
uplo         [ type = int ]
descA        [ type = "parsec_tiled_matrix_dc_t*" ]
descAr       [ type = "parsec_tiled_matrix_dc_t*" ]
descRG       [ type = "parsec_tiled_matrix_dc_t*" aligned = descA ]
descRank     [ type = "parsec_tiled_matrix_dc_t*" aligned = descA ]
INFO         [ type = "int*" ]
acc          [ type = "double" ]
rk           [ type = "int" ]
storage_maxrank        [ type = "int" ]
computation_maxrank    [ type = "int" ]
lookahead    [ type = "int" ]

p_work       [ type = "parsec_memory_pool_t *" hidden = on default = NULL ] 
p_work_rr    [ type = "parsec_memory_pool_t *" hidden = on default = NULL ]
p_work_mbr   [ type = "parsec_memory_pool_t *" hidden = on default = NULL ]
d_work       [ type = "parsec_memory_pool_t *" hidden = on default = NULL ]
rsvd_work    [ type = "parsec_memory_pool_t *" hidden = on default = NULL ]
rsvd_iwork   [ type = "parsec_memory_pool_t *" hidden = on default = NULL ]
rsvd_oversample   [ type = "int" hidden = on default = 10 ]
rsvd_lwork   [ type = "int" hidden = on default = "descA->mb * descA->mb * 8" ]
band_size    [ type = "int" hidden = on default = 1 ] 

PRI_CHANGE   [ type = "int" hidden = on default = 0 ]
PRI_MAX      [ type = "int" hidden = on default = "(descA->mt * ( 3 + descA->mt * ( 2 + descA->mt )))" ]
smallnb      [ type = "int" hidden = on default = 300 ]

enable_potrf [ type = "int" hidden = on default = 1 ]
enable_trsm  [ type = "int" hidden = on default = 1 ]
enable_syrk  [ type = "int" hidden = on default = 1 ]
enable_gemm  [ type = "int" hidden = on default = 1 ]
verbose_r    [ type = "int" hidden = on default = 0 ]
send_full_tile       [ type = "int" hidden = on default = 0 ]

tileopcounters       [ type = "unsigned long*" hidden = on default = NULL ]
opcounters           [ type = "unsigned long*" hidden = on default = NULL ]

potrf_time           [ type = "double*" hidden = on default = 0 ]
trsm_time            [ type = "double*" hidden = on default = 0 ]
syrk_time            [ type = "double*" hidden = on default = 0 ]
potrf_time_temp      [ type = "double*" hidden = on default = 0 ]
trsm_time_temp       [ type = "double*" hidden = on default = 0 ]
syrk_time_temp       [ type = "double*" hidden = on default = 0 ]
wrap_potrf           [ type = "parsec_hook_t*" hidden = on default = NULL ]
wrap_trsm            [ type = "parsec_hook_t*" hidden = on default = NULL ]
wrap_syrk            [ type = "parsec_hook_t*" hidden = on default = NULL ]
wrap_gemm            [ type = "parsec_hook_t*" hidden = on default = NULL ]
wrap_potrf_complete  [ type = "parsec_hook_t*" hidden = on default = NULL ]
wrap_trsm_complete   [ type = "parsec_hook_t*" hidden = on default = NULL ]
wrap_syrk_complete   [ type = "parsec_hook_t*" hidden = on default = NULL ]
wrap_gemm_complete   [ type = "parsec_hook_t*" hidden = on default = NULL ]

have_compression     [ type = "int" hidden = on default = 0 ]
two_step_hcore_gemm  [ type = "int" hidden = on default = 1 ]

/* GPU workspace */
ws_handle            [ type = "void *" hidden = on default = NULL ]
ws_mbr               [ type = "void *" hidden = on default = NULL ]
ws_rr                [ type = "void *" hidden = on default = NULL ]

nb_cuda_devices      [ type = "int"   hidden = on default = 0 ]
cuda_device_index    [ type = "int *" hidden = on default = "NULL"]

READ_Cr(m, n)

m = band_size .. descA->mt-1
n = 0 .. m-band_size

:descAr(m, n)

READ Cr <- descAr(m, n)                                        [ type = AR ]
        -> (n == 0) ? Cr potrf_dtrsm(m, n)                     [ type = AR ]
        -> (n != 0) ? Cr potrf_dgemm(m, n, 0)                  [ type = AR ]

BODY
{
    if(verbose_r) printf("READ_Cr(%d, %d)\n", m, n);
}
END

WRITE_Cr(m, k)

m = band_size .. descA->mt-1
k = 0 .. m-band_size

:descAr(m, k)

READ Cr <- Cr potrf_dtrsm(m, k)                [ type = AR ]
        -> descAr(m, k)                      [ type = AR ]

BODY
{
    if(verbose_r) printf("WRITE_Cr(%d, %d)\n", m, k);
}
END

/**************************************************
 *               potrf_dpotrf                     *
 **************************************************/
potrf_dpotrf(k) [high_priority = on]

// Execution space
k = 0 .. descA->mt-1

// Parallel partitioning
:descA(k, k)

// Parameters
RW T <- (k == 0) ? descA(k, k) : T potrf_dsyrk(k-1, k)   [ type = FULL ]
     -> T potrf_dtrsm(k+1..descA->mt-1, k)               [ type = FULL ]
     -> descA(k, k)                                      [ type = FULL ]

; (k >= (descA->mt - PRI_CHANGE)) ? (descA->mt - k) * (descA->mt - k) * (descA->mt - k) : PRI_MAX

BODY [type=CUDA weight=k+1]
{
#if defined(PARSEC_HAVE_CUDA)
    if( DEBUG_INFO ) printf("GPU_potrf %d\n", k);
    int tempkn = k == descA->nt-1 ? descA->n - k*descA->nb : descA->nb;
    int ldak = BLKLDD( descA, k );
    cusolverStatus_t status;

    /* Lookup workspace */
    parsec_potrf_stream_workspace_t stream_handle = lookup_gpu_workspace(gpu_device, gpu_stream, ws_handle);

    /* Info used on GPU kernel */
    cusolverDnHandle_t handle = stream_handle.handle;
    int *dev_info = (int *)(stream_handle.gpu_buffer + stream_handle.buffer_size * sizeof(double));
    double *gpu_buffer = (double *)stream_handle.gpu_buffer;
    int buffer_size = stream_handle.buffer_size;
    assert(NULL != gpu_buffer);

    /* GPU kernel */
    status = cusolverDnDpotrf(handle, CUBLAS_FILL_MODE_LOWER, tempkn, T, ldak, gpu_buffer, buffer_size, dev_info);
    assert(CUSOLVER_STATUS_SUCCESS == status);

    /* We are losing the iinfo in d_iinfo, because the kernel is asynchronous.
     * We should register a complete function to read d_iinfo back in CPU memory,
     * and update INFO with it... */
#endif
}
END


BODY [type=RECURSIVE]
{
    if(enable_potrf == 0) return PARSEC_HOOK_RETURN_DONE;
    int tempkm = k == descA->mt-1 ? descA->m - k*descA->mb : descA->mb;
    int iinfo = 0;

    /* Operation count */
    unsigned long int cnt = ka_counts('c', tempkm, 0, 0, 0);
    LOG_OPCOUNT(cnt, k, k);
    op_band[es->th_id] += cnt;
    op_path[es->th_id] += cnt;

    if( descA->mt/100 && 0 == k % (descA->mt/100) )
        fprintf(stderr, "In potrf, k %d, %.2lf %% is finished\n", k, 100.0*k/descA->mt);

    if( tempkm > smallnb )
    {
        if(DEBUG_INFO) printf("POTRF Recursive: %d\n", k);

        subtile_desc_t *small_descT;
        parsec_taskpool_t *parsec_dpotrf;

        small_descT = subtile_desc_create( descA, k, k,
                                           smallnb, smallnb, 0, 0, tempkm, tempkm );
        small_descT->mat = T;

        parsec_dpotrf = dplasma_dpotrf_New(uplo, (parsec_tiled_matrix_dc_t *)small_descT, &iinfo );

        parsec_recursivecall(es, (parsec_task_t*)this_task,
                             parsec_dpotrf, dplasma_dpotrf_Destruct,
                             1, small_descT);

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go for the sequential CPU version */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    if(enable_potrf == 0) return PARSEC_HOOK_RETURN_DONE;
    int tempkm = k == descA->mt-1 ? descA->m - k*descA->mb : descA->mb;
    int iinfo = 0;
    int ld_Ag_k = BLKLDD( descA, k );
    if(DEBUG_INFO) printf("DPOTRF: %d\n", k);

#if !defined(PARSEC_DRY_RUN)
    iinfo = HiCMA_HCORE_dpotrf( uplo, tempkm, T, ld_Ag_k, k, 0 );
    if ( iinfo != 0 && *INFO == 0 )
            *INFO = k*descA->mb+iinfo; /* Should return here */
#endif /* !defined(PARSEC_DRY_RUN) */
    printlog("HCORE_dpotrf( %d )\n\t( %s, %d, A(%d,%d)[%p], %d) return info = %d\n", k, plasma_const(uplo), tempkm, k, 0, T, descA->mb, iinfo);

    if(verbose_r) printf("DPOTRF(%d)\n", k);
}
END

/**************************************************
 *               potrf_dtrsm                      *
 **************************************************/
potrf_dtrsm(m, k) [high_priority = on]

// Execution space
m = 1 .. descA->mt-1
k = 0 .. m-1

// Control message size to send, it's the new Cr
size = 1

// Added for evaluated of gpu chores
band_size_local = band_size

// Parallel partitioning
: descA(m, k)

// Parameters
READ  T <- T potrf_dpotrf(k)                                                 [ type = FULL ]

RW    C <- (k == 0 && m-k < band_size) ? descA(m, k)                         [ type = FULL ]
        <- (k != 0 && m-k < band_size) ? C potrf_dgemm(m, k, k-1) : NULL                      [ type = FULL ]
        -> (m-k < band_size) ? A potrf_dsyrk(k, m)                           [ type = FULL ]
        -> (m-k < band_size) ? A potrf_dgemm(m, k+1..m-1, k)                 [ type = FULL ]
        -> (m-k < band_size) ? B potrf_dgemm(m+1 .. descA->mt-1, m, k)       [ type = FULL ]
        -> (m-k < band_size) ? descA(m, k)                                   [ type = FULL ]

RW    Cu <- (k == 0 && m-k >= band_size) ? descA(m, k)                        [ type = UV ]
         <- (k != 0 && m-k >= band_size) ? Cu potrf_dgemm(m, k, k-1) : NULL                                          [ type = UV ]
         -> (m-k >= band_size) ? Au potrf_dsyrk(k, m)                         [ layout = MPI_DOUBLE count = size ]
         -> (m-k >= band_size) ? Au potrf_dgemm(m, k+1..m-1, k)               [ layout = MPI_DOUBLE count = size ]
         -> (m-k >= band_size) ? Bu potrf_dgemm(m+1..descA->mt-1, m, k)       [ layout = MPI_DOUBLE count = size ]
         -> (m-k >= band_size) ? descA(m, k)                                 [ layout = MPI_DOUBLE count = size ]

RW    Cv <- (m-k >= band_size) ? NEW: NULL                        [ type = UV ]
         -> (m-k >= band_size) ? Av potrf_dsyrk(k, m)                         [ layout = MPI_DOUBLE count = size ]
         -> (m-k >= band_size) ? Av potrf_dgemm(m, k+1..m-1, k)               [ layout = MPI_DOUBLE count = size ]
         -> (m-k >= band_size) ? Bv potrf_dgemm(m+1..descA->mt-1, m, k)       [ layout = MPI_DOUBLE count = size ]

READ  Cr <- (k == 0 && m-k >= band_size) ? Cr READ_Cr(m, k)                  [ type = AR ]
         <- (k != 0 && m-k >= band_size) ? Cr potrf_dgemm(m, k, k-1): NULL   [ type = AR ]
         -> (m-k >= band_size) ? Ar potrf_dsyrk(k, m)                        [ type = AR ] 
         -> (m-k >= band_size) ? Ar potrf_dgemm(m, k+1..m-1, k)              [ type = AR ] 
         -> (m-k >= band_size) ? Br potrf_dgemm(m+1..descA->mt-1, m, k)      [ type = AR ] 
         -> (m-k >= band_size) ? Cr WRITE_Cr(m, k)                           [ type = AR ] 

CTL ctl <- (lookahead == 1 && m > lookahead+k)? ctl potrf_dsyrk(k, k+1)
CTL ctl1 <- (lookahead > 1 && m > lookahead+k)? ctl2 potrf_dtrsm(k+2, k)
CTL ctl2 -> (lookahead > 1 && m == k+2)? ctl1 potrf_dtrsm(lookahead+k+1 .. descA->mt-1, k)

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * ((2 * descA->mt) - k - m - 1) * (m - k) : PRI_MAX

BODY [type=CUDA weight=(m+1-k)]
{
#if defined(PARSEC_HAVE_CUDA)
    if( DEBUG_INFO ) printf("GPU_trsm %d %d\n", m, k);
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldak = BLKLDD( descA, k );
    int ldam = BLKLDD( descA, m );

    if ( m-k < band_size ) {
        if(DEBUG_INFO) printf("GPU_trsm %d %d\n", m, k);
        cublasStatus_t status;
        cublasSetKernelStream( parsec_body.stream );
        cublasDtrsm('R', 'L', 'T', 'N',
                   tempmm, descA->mb,
                   (double)1.0, T /*A(k, k)*/, ldak,
                                C /*A(m, k)*/, ldam);
        status = cublasGetError();
        PARSEC_CUDA_CHECK_ERROR( "cublasDtrsm ", status,
                                {return -1;} );
    }
    else
        /* Go to CPU kernel */
        return PARSEC_HOOK_RETURN_NEXT;
#endif
}
END

BODY [type=RECURSIVE]
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;

    /* Operation count */
    if( m-k < band_size ) { 
        unsigned long int cnt = ka_counts('t', tempmm, tempmm, 1 /*side*/, 0);
        LOG_OPCOUNT(cnt, m, k);
        op_band[es->th_id] += cnt;
        if( 1 == m-k )
            op_path[es->th_id] += cnt;
        else
            op_offpath[es->th_id] += cnt;
    } else {
        unsigned long int cnt = ka_counts('t', tempmm, ((int*)Cr)[0], 1 /*side*/, 0);
        LOG_OPCOUNT(cnt, m, k);
        op_offband[es->th_id] += cnt;
        if( 1 == m-k )
            op_path[es->th_id] += cnt;
        else
            op_offpath[es->th_id] += cnt;
    }

    if ( (m-k < band_size) && (tempmm > smallnb) )
    {
        if(DEBUG_INFO) printf("TRSM Recursive: %d %d ; mb %d, nb: %d, band_size: %d\n", m, k, descA->mb, descA->nb, band_size);

        subtile_desc_t *small_descT;
        subtile_desc_t *small_descC;
        parsec_taskpool_t* parsec_dtrsm;

        small_descT = subtile_desc_create( descA, k, k,
                                           smallnb, smallnb, 0, 0, descA->mb, descA->mb );
        small_descT->mat = T;

        small_descC = subtile_desc_create( descA, m, k,
                                           smallnb, smallnb, 0, 0, tempmm, descA->mb );
        small_descC->mat = C;

        parsec_dtrsm = dplasma_dtrsm_New(PlasmaRight, PlasmaLower,
                                        PlasmaTrans, PlasmaNonUnit,
                                        (double)1.0,
                                        (parsec_tiled_matrix_dc_t *)small_descT,
                                        (parsec_tiled_matrix_dc_t *)small_descC );

        parsec_recursivecall(es, (parsec_task_t*)this_task,
                             parsec_dtrsm, dplasma_dtrsm_Destruct,
                             2, small_descT, small_descC );

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go for the sequential CPU version */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    //printf("enable trsm:%d\n", enable_trsm);
    if(enable_trsm == 0) return PARSEC_HOOK_RETURN_DONE;
    if(DEBUG_INFO) printf("TRSM: %d %d ; mb %d, nb: %d, band_size: %d\n", m, k, descA->mb, descA->nb, band_size);

    if( m-k < band_size ) {
        int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
        int ldak = BLKLDD( descA, k );
        int ldam = BLKLDD( descA, m );

#if !defined(PARSEC_DRY_RUN)
        CORE_dtrsm(PlasmaRight, PlasmaLower, PlasmaTrans, PlasmaNonUnit,
                   tempmm, descA->mb,
                   (double)1.0, T /*A(k, k)*/, ldak,
                                           C /*A(m, k)*/, ldam);
#endif  /* !defined(PARSEC_DRY_RUN) */

        printlog("CORE_dtrsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
                 m, k,
                 plasma_const( PlasmaRight ), plasma_const( PlasmaLower ),
                 plasma_const( PlasmaTrans ), plasma_const( PlasmaNonUnit ),
                 tempmm, descA->mb,
                 1.0, k, k, T, ldak,
                      m, k, C, ldam);

    } else {
        int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
        int ldak = BLKLDD( descA, k );
        int ldam = BLKLDD( descA, m );
        memcpy( Cv, (void *)Cu + descA->mb * ((int *)Cr)[0] * sizeof(double), descA->mb * ((int *)Cr)[0] * sizeof(double) );

#if !defined(PARSEC_DRY_RUN)
        HiCMA_HCORE_dtrsm(PlasmaLeft, PlasmaLower, PlasmaNoTrans, PlasmaNonUnit,
                   tempmm, descA->mb, (double)1.0, T, ldak,
                   Cv, ldam, Cr, k, 0, m, k);
#endif  /* !defined(PARSEC_DRY_RUN) */

        printlog("HCORE_dtrsm( %d, %d )\n\t( %s, %s, %s, %s, %d, %d, %f, A(%d,%d)[%p], %d,  A(%d,%d)[%p], %d)\n",
                 m, k,
                 plasma_const( PlasmaRight ), plasma_const( PlasmaLower ),
                 plasma_const( PlasmaTrans ), plasma_const( PlasmaNonUnit ),
                 tempmm, descA->mb,
                 1.0, k, k, T, ldak,
                      m, k, Cv, ldam);

        /* Pass Cr value to size */
        if(send_full_tile == 1){
            this_task->locals.size.value = descA->mb * storage_maxrank;
        } else {
            this_task->locals.size.value = descA->mb * ((int *)Cr)[0];
        }

        memcpy( (void *)Cu + descA->mb * ((int *)Cr)[0] * sizeof(double), Cv, descA->mb * ((int *)Cr)[0] * sizeof(double) );

        if(verbose_r) printf("Cr value in DTRSM (%d, %d): %d\n", m, k, ((int *)Cr)[0]);
    }

if(DEBUG_INFO) printf("TRSM: %d %d END; mb %d, nb: %d, band_size: %d\n", m, k, descA->mb, descA->nb, band_size);

}
END


/**************************************************
 *               potrf_dsyrk                      *
 **************************************************/
potrf_dsyrk(k, m) [high_priority = on]

// Execution space
k = 0   .. descA->mt-2
m = k+1 .. descA->mt-1

// Added for evaluated of gpu chores
band_size_local = band_size

// Parallel partitioning
: descA(m, m)

//Parameters
READ  A <- (m-k < band_size) ? C potrf_dtrsm(m, k) : NULL                      [ type = FULL ]
READ  Au <- (m-k >= band_size) ? Cu potrf_dtrsm(m, k) : NULL                   [ type = UV ]
READ  Av <- (m-k >= band_size) ? Cv potrf_dtrsm(m, k) : NULL                   [ type = UV ]

READ  Ar <- (m-k >= band_size) ? Cr potrf_dtrsm(m, k): NULL             [ type = AR ]

RW    T <- (k == 0) ? descA(m, m) : T potrf_dsyrk(k-1, m)               [ type = FULL ] 
        -> (m == k+1) ? T potrf_dpotrf(m) : T potrf_dsyrk(k+1, m)       [ type = FULL ]

CTL ctl -> (lookahead == 1 && m == k+1)? ctl potrf_dtrsm(lookahead+m .. descA->mt-1, k)

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * (m - k) : PRI_MAX

BODY [type=CUDA weight=(m+1-k)]
{
#if defined(PARSEC_HAVE_CUDA)
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;
    int ldam = BLKLDD( descA, m );

    if ( m-k < band_size ) {
        if( DEBUG_INFO ) printf("GPU_syrk of 'm-k < band_size':  %d %d\n", m, k);
        cublasStatus_t status;
        cublasSetKernelStream( parsec_body.stream );
#if !defined(PARSEC_DRY_RUN)
        cublasDsyrk('L', 'N',
                   tempmm, descA->mb,
                   (double)-1.0, A /*A(m, k)*/, ldam,
                   (double) 1.0, T /*A(m, m)*/, ldam);
        status = cublasGetError();
        PARSEC_CUDA_CHECK_ERROR( "cublasDtrsm ", status,
                                {return -1;} );
#endif
    }
    else {
        if( DEBUG_INFO ) printf("GPU_syrk of 'm-k >= band_size':  %d %d\n", m, k);

        /* Get Arank on CPU */
        int Arank = ((int *)this_task->data._f_Ar.data_in->original->device_copies[0]->device_private)[0]; 

        /* Au, Av, Bu, Bv */
        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * Arank * sizeof(double);

        /* Get the temporary buffer */
        parsec_potrf_stream_workspace_t stream_mbr = lookup_gpu_workspace(gpu_device, gpu_stream, ws_mbr);
        double *my_buffer_mbr = (double *)stream_mbr.gpu_buffer;
        assert(NULL != my_buffer_mbr);

        parsec_potrf_stream_workspace_t stream_rr = lookup_gpu_workspace(gpu_device, gpu_stream, ws_rr);
        double *my_buffer_rr = (double *)stream_rr.gpu_buffer;
        assert(NULL != my_buffer_rr);

#if !defined(PARSEC_DRY_RUN)
        /* tmp_rr = trans(Av) * Av */
        cublasDgemm('T', 'N',
                   Arank, Arank, descA->mb,
                   (double) 1.0, Av             /*A(k, m)*/, descA->mb,
                                 Av             /*A(k, n)*/, descA->mb,
                   (double) 0.0, my_buffer_rr   /*A(m, n)*/, Arank);

        /* tmp_mbr = tmp_rr * trans(Au) */
        cublasDgemm('N', 'T',
                    Arank, descA->mb, Arank,
                    (double) 1.0, my_buffer_rr    /*A(m, k)*/, Arank,
                                  Au              /*A(n, k)*/, descA->mb,
                    (double) 0.0, my_buffer_mbr   /*A(m, n)*/, Arank);

        /* T = T - Au * tmp_mbr */
        cublasDgemm('N', 'N',
                    descA->mb, descA->mb, Arank,
                    (double)-1.0, Au              /*A(m, k)*/, descA->mb,
                                  my_buffer_mbr   /*A(k, n)*/, Arank,
                    (double) 1.0, T               /*A(m, n)*/, descA->mb);
#endif
    }

#endif
}
END

BODY [type=RECURSIVE]
{
    if(enable_syrk == 0) return PARSEC_HOOK_RETURN_DONE;
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;

    /* Operation count */
    if( m-k < band_size ) {
        unsigned long int cnt = ka_counts('m', tempmm, tempmm, tempmm, 0);
        LOG_OPCOUNT(cnt, m, m);
        op_band[es->th_id] += cnt;
        if( 1 == m-k )
            op_path[es->th_id] += cnt;
        else
            op_offpath[es->th_id] += cnt;
    } else {
        int rank = ((int*)Ar)[0];
        /// C = C + alpha * A * A'
        /// C = C + alpha * ( (A^u * (A^v * A^v^T) ) * A^u^T)
        unsigned long int cnt = 0;
        /// A^v * B^v^T
        cnt += ka_counts('m', rank, rank, tempmm, 0);
        /// A^u * (A^v * B^v^T)
        cnt += ka_counts('m', tempmm, rank, rank, 0);
        /// (A^u * (A^v * B^v^T) ) * B^u^T
        cnt += ka_counts('m', tempmm, tempmm, rank, 0);
        LOG_OPCOUNT(cnt, m, m);
        op_band[es->th_id] += cnt;
        if( 1 == m-k )
            op_path[es->th_id] += cnt;
        else
            op_offpath[es->th_id] += cnt;
    }

    /* If recursive */
    if ( (m-k < band_size) && (tempmm > smallnb) )
    {
        if(DEBUG_INFO) printf("SYRK Recursive %d %d \n", k, m);
        subtile_desc_t *small_descT;
        subtile_desc_t *small_descA;
        parsec_taskpool_t* parsec_dsyrk;

        small_descT = subtile_desc_create( descA, m, m,
                                           smallnb, smallnb, 0, 0, tempmm, tempmm );
        small_descT->mat = T;

        small_descA = subtile_desc_create( descA, m, k,
                                           smallnb, smallnb, 0, 0, tempmm, descA->mb );
        small_descA->mat = A;

        parsec_dsyrk = dplasma_dsyrk_New( PlasmaLower, PlasmaNoTrans,
                                         (double)-1.0, (parsec_tiled_matrix_dc_t*) small_descA,
                                         (double)1.0,  (parsec_tiled_matrix_dc_t*) small_descT);

        parsec_recursivecall(es, (parsec_task_t*)this_task,
                             parsec_dsyrk, dplasma_dsyrk_Destruct,
                             2, small_descA, small_descT);
        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go for the sequential CPU version */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    if(enable_syrk == 0) return PARSEC_HOOK_RETURN_DONE;
    if(DEBUG_INFO) printf("SYRK: %d %d\n", m, k);
    int tempmm = m == descA->mt-1 ? descA->m - m*descA->mb : descA->mb;
    int ldam = BLKLDD( descA, m );

    /* No recursive, dense SYRK or low rank LR_SYRK */
    if( m-k < band_size ) {
#if !defined(PARSEC_DRY_RUN)
        CORE_dsyrk(PlasmaLower, PlasmaNoTrans,
                   tempmm, descA->mb,
                   (double)-1.0, A /*A(m, k)*/, ldam,
                   (double) 1.0, T /*A(m, m)*/, ldam);
#endif  /* !defined(PARSEC_DRY_RUN) */
        printlog(
                 "CORE_dsyrk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
                 k, m,
                 plasma_const( PlasmaLower ), plasma_const( PlasmaNoTrans ),
                 tempmm, descA->mb,
                 -1.0, m, k, A, ldam,
                  1.0, m, m, T, ldam);
    } else {
        int ldau = BLKLDD( descA, m );
        int ldav = BLKLDD( descA, m );
        int rank = ((int*)Ar)[0];
        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * rank * sizeof(double);
        int call_hcore_dsyrk = 1;

#if !defined(PARSEC_DRY_RUN)
#if call_hcore_dsyrk
        void *p_elem_work = parsec_private_memory_pop( p_work );
        HiCMA_HCORE_dsyrk(PlasmaLower, PlasmaNoTrans,
                   tempmm, rank,
                   (double)-1.0, 
                   Au /*A(m, k)*/, ldau,
                   Av /*A(m, k)*/, ldav,
                   (double) 1.0, T /*A(m, m)*/, ldam, p_elem_work);
        parsec_private_memory_push( p_work, p_elem_work );

/* if want to call 3 gemms instead of HiCMA_HCORE_dsyrk */
#else
        void *p_elem_work_mbr = parsec_private_memory_pop( p_work_mbr );
        void *p_elem_work_rr = parsec_private_memory_pop( p_work_rr );

        /* tmp_rr = trans(Av) * Av */
        CORE_dgemm(PlasmaTrans, PlasmaNoTrans,
                   rank, rank, descA->mb,
                   (double) 1.0, Av             /*A(k, m)*/, descA->mb,
                                 Av             /*A(k, n)*/, descA->mb,
                   (double) 0.0, p_elem_work_rr /*A(m, n)*/, rank);

        /* tmp_mbr = tmp_rr * trans(Au) */
        CORE_dgemm(PlasmaNoTrans, PlasmaTrans,
                   rank, descA->mb, rank,
                   (double) 1.0, p_elem_work_rr  /*A(m, k)*/, rank,
                                 Au              /*A(n, k)*/, descA->mb,
                   (double) 0.0, p_elem_work_mbr /*A(m, n)*/, rank);

        /* T = T - Au * tmp_mbr */
        CORE_dgemm(PlasmaNoTrans, PlasmaNoTrans,
                   descA->mb, descA->mb, rank,
                   (double)-1.0, Au              /*A(m, k)*/, descA->mb,
                                 p_elem_work_mbr /*A(k, n)*/, rank,
                   (double) 1.0, T               /*A(m, n)*/, descA->mb);

        parsec_private_memory_push( p_work_mbr, p_elem_work_mbr );
        parsec_private_memory_push( p_work_rr, p_elem_work_rr );
#endif

#endif  /* !defined(PARSEC_DRY_RUN) */
        printlog(
                 "HCORE_dsyrk( %d, %d )\n\t( %s, %s, %d, %d, %f, A(%d,%d)[%p], %d, %f, A(%d,%d)[%p], %d)\n",
                 k, m,
                 plasma_const( PlasmaLower ), plasma_const( PlasmaNoTrans ),
                 tempmm, descA->mb,
                 -1.0, m, k, Av, ldam,
                  1.0, m, 0, T, ldam);

        if(verbose_r) printf("SYRK(%d, %d)\n", k, m);
    }
}
END

/**************************************************
 *               potrf_dgemm                      *
 **************************************************/
// Name
potrf_dgemm(m, n, k)

// Execution space
k = 0   .. descA->mt-3
m = k+2 .. descA->mt-1
n = k+1 .. m-1

// Control message size to send, it's the new Cr
size = 1

// Added for evaluated of gpu chores
band_size_local = band_size
send_full_tile_local = send_full_tile

//k_pre = %{ return define_k_pre(descRG, m, n, k); %} 
//k_next = %{ return define_k_next(descRG, m, n, k); %} 
k_pre = k-1
k_next = k+1

// Parallel partitioning
: descA(m, n)

// Parameters
READ   A <- (m-k < band_size) ? C potrf_dtrsm(m, k) : NULL                                    [ type = FULL ] 
READ  Au <- (m-k >= band_size) ? Cu potrf_dtrsm(m, k) : NULL                                         [ type = UV ]                
READ  Av <- (m-k >= band_size) ? Cv potrf_dtrsm(m, k) : NULL                                         [ type = UV ]                
READ  Ar <- (m-k >= band_size) ? Cr potrf_dtrsm(m, k) : NULL                            [ type = AR ]

READ   B <- (n-k < band_size) ? C potrf_dtrsm(n, k) : NULL                [ type = FULL ] 
READ  Bu <- (n-k >= band_size) ? Cu potrf_dtrsm(n, k) : NULL                             [ type = UV ]
READ  Bv <- (n-k >= band_size) ? Cv potrf_dtrsm(n, k) : NULL                             [ type = UV ]
READ  Br <- (n-k >= band_size) ? Cr potrf_dtrsm(n, k): NULL                                 [ type = AR ]

RW     C <- (k == 0 && m-n < band_size) ? descA(m, n)                                  [ type = FULL ]
         <- (k != 0 && m-n < band_size) ? C potrf_dgemm(m, n, k_pre) : NULL                             [ type = FULL ]
         -> (n == k+1 && m-n < band_size) ? C potrf_dtrsm(m, n)                        [ type = FULL ]
         -> (n != k+1 && m-n < band_size) ? C potrf_dgemm(m, n, k_next)                [ type = FULL ]

RW    Cu <- (k == 0 && m-n >= band_size) ? descA(m, n)                                 [ type = UV ]
         <- (k != 0 && m-n >= band_size) ? Cu potrf_dgemm(m, n, k_pre) : NULL                                                [ type = UV ]
         -> (n == k+1 && m-n >= band_size) ? Cu potrf_dtrsm(m, n)                       [ layout = MPI_DOUBLE count = size ]
         -> (n != k+1 && m-n >= band_size) ? Cu potrf_dgemm(m, n, k_next)               [ layout = MPI_DOUBLE count = size ]

RW    Cr <- (k == 0 && m-n >= band_size) ? Cr READ_Cr(m, n)                            [ type = AR ]
         <- (k != 0 && m-n >= band_size) ? Cr potrf_dgemm(m, n, k_pre): NULL           [ type = AR ]
         -> (n == k+1 && m-n >= band_size) ? Cr potrf_dtrsm(m, n)                      [ type = AR ]
         -> (n != k+1 && m-n >= band_size) ? Cr potrf_dgemm(m, n, k_next)              [ type = AR ]

; (m >= (descA->mt - PRI_CHANGE)) ? (descA->mt - m) * (descA->mt - m) * (descA->mt - m) + 3 * ((2 * descA->mt) - m - n - 3) * (m - n) + 6 * (m - k) : PRI_MAX

BODY [type=CUDA weight=(n+1-k)]
{
#if defined(PARSEC_HAVE_CUDA)
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
    int ldam = BLKLDD( descA, m );
    int ldan = BLKLDD( descA, n );

    cublasStatus_t status;
    cudaError_t err;
    cublasSetKernelStream( parsec_body.stream );
    parsec_potrf_stream_workspace_t wp_mbr;
    parsec_potrf_stream_workspace_t wp_rr;

    if ( m-k < band_size ) {
        if( DEBUG_INFO ) printf("GPU_gemm of 'm-k < band_size': %d %d %d; band_size: %d\n", m, n, k, band_size);
        cublasDgemm( 'N', 'T',
                 tempmm, descA->mb, descA->mb,
                 (double)-1.0, (double*)A, ldam,
                        (double*)B, ldan,
                 (double)1.0,  (double*)C, ldam );
        status = cublasGetError();
        PARSEC_CUDA_CHECK_ERROR( "cublasDgemm_1 ", status,
                                {return -1;} );
    //} else if( n-k < band_size && m-n < band_size && send_full_tile ) {
    } else if( n-k < band_size && m-n < band_size ) {
        if( DEBUG_INFO ) printf("GPU_gemm of 'n-k < band_size && m-n < band_size':  %d %d %d; band_size: %d\n", m, n, k, band_size);
        /* Get Arank on CPU */
        int Arank = ((int *)this_task->data._f_Ar.data_in->original->device_copies[0]->device_private)[0]; 

        /* Au and Av */
        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * Arank * sizeof(double);

        /* Get the temporary buffer */
        wp_mbr = lookup_gpu_workspace(gpu_device, gpu_stream, ws_mbr);
        double *my_buffer_mbr = (double *)wp_mbr.gpu_buffer;
        assert(NULL != my_buffer_mbr);

#if !defined(PARSEC_DRY_RUN)
        /* tmp_mbr = trans(Av) * trans(B) */
        cublasDgemm('T', 'T',
                   Arank, descA->mb, descA->mb,
                   (double)1.0, Av /*A(m, k)*/, descA->mb,
                                 B /*A(n, m)*/, descA->mb,
                   (double) 0.0, my_buffer_mbr /*A(k, n)*/, Arank);
        status = cublasGetError();
        PARSEC_CUDA_CHECK_ERROR( "cublasDgemmi_2 ", status,
                                {return -1;} );

        /* C = C - Au * tmp_mbr */
        cublasDgemm('N', 'N',
                   descA->mb, descA->mb, Arank,
                   (double)-1.0, Au              /*A(m, k)*/, descA->mb,
                                 my_buffer_mbr /*A(k, n)*/, Arank,
                   (double) 1.0, C               /*A(m, n)*/, descA->mb);
        status = cublasGetError();
        PARSEC_CUDA_CHECK_ERROR( "cublasDgemm_3 ", status,
                                {return -1;} );
#endif  /* !defined(PARSEC_DRY_RUN) */

    //} else if( m-n < band_size && send_full_tile) {
    } else if( m-n < band_size ) {
        if( DEBUG_INFO ) printf("GPU_gemm of 'm-n < band_size':  %d %d %d\n", m, n, k);

        /* Get Arank on CPU */
        int Arank = ((int *)this_task->data._f_Ar.data_in->original->device_copies[0]->device_private)[0]; 
        int Brank = ((int *)this_task->data._f_Br.data_in->original->device_copies[0]->device_private)[0]; 

        /* Au, Av, Bu, Bv */
        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * Arank * sizeof(double);
        //void *Bu = (void *)B;
        //void *Bv = (void *)B + descA->mb * Brank * sizeof(double);

        /* Get the temporary buffer */
        wp_mbr = lookup_gpu_workspace(gpu_device, gpu_stream, ws_mbr);
        double *my_buffer_mbr = (double *)wp_mbr.gpu_buffer;
        assert(NULL != my_buffer_mbr);

        wp_rr = lookup_gpu_workspace(gpu_device, gpu_stream, ws_rr);
        double *my_buffer_rr = (double *)wp_rr.gpu_buffer;
        assert(NULL != my_buffer_rr);

#if !defined(PARSEC_DRY_RUN)
        /* tmp_rr = trans(Av) * Bv */
        cublasDgemm('T', 'N',
                   Arank, Brank, descA->mb,
                   (double) 1.0, Av             /*A(k, m)*/, descA->mb,
                                 Bv             /*A(k, n)*/, descA->mb,
                   (double) 0.0, my_buffer_rr   /*A(m, n)*/, Arank);

        if( Arank > Brank ) {
            /* tmp_mbr = Au * tmp_rr */
            cublasDgemm('N', 'N',
                       descA->mb, Brank, Arank,
                       (double) 1.0, Au              /*A(m, k)*/, descA->mb,
                                     my_buffer_rr    /*A(k, n)*/, Arank,
                       (double) 0.0, my_buffer_mbr   /*A(m, n)*/, descA->mb);

            /* C = C - tmp_mbr * trans(Bu) */
            cublasDgemm('N', 'T',
                       descA->mb, descA->mb, Brank,
                       (double)-1.0, my_buffer_mbr   /*A(m, k)*/, descA->mb,
                                     Bu              /*A(n, k)*/, descA->mb,
                       (double) 1.0, C               /*A(m, n)*/, descA->mb);
        } else {
            /* tmp_mbr = tmp_rr * trans(Bu) */
            cublasDgemm('N', 'T',
                       Arank, descA->mb, Brank,
                       (double) 1.0, my_buffer_rr    /*A(m, k)*/, Arank,
                                     Bu              /*A(n, k)*/, descA->mb,
                       (double) 0.0, my_buffer_mbr   /*A(m, n)*/, Arank);

            /* C = C - Au * tmp_mbr */
            cublasDgemm('N', 'N',
                       descA->mb, descA->mb, Arank,
                       (double)-1.0, Au              /*A(m, k)*/, descA->mb,
                                     my_buffer_mbr   /*A(k, n)*/, Arank,
                       (double) 1.0, C               /*A(m, n)*/, descA->mb);
        }
#endif  /* !defined(PARSEC_DRY_RUN) */

    } else
        /* Go to CPU kernel */
        return PARSEC_HOOK_RETURN_NEXT;
#endif
}
END

BODY [type=RECURSIVE]
{
    int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;

    /* Operation count on band*/
    if ( m-k < band_size ) {
        unsigned long int cnt = ka_counts('m', tempmm, tempmm, tempmm, 0);
        LOG_OPCOUNT(cnt, m, n);
        op_band[es->th_id] += cnt;
        op_offpath[es->th_id] += cnt;
    } else if( n-k < band_size && m-n < band_size ) {
        int Arank = ((int*)Ar)[0];
        unsigned long int cnt = ka_counts('m', tempmm, tempmm, Arank, 0) * 2;
        LOG_OPCOUNT(cnt, m, n);
        op_band[es->th_id] += cnt;
        op_offpath[es->th_id] += cnt;
    } else if( m-n < band_size ) {
        int Arank = ((int*)Ar)[0];
        int Brank = ((int*)Br)[0];
        unsigned long int cnt = ka_counts('m', tempmm, tempmm, min(Arank, Brank), 0)
                                + ka_counts('m', tempmm, Arank, Brank, 0) * 2;
        LOG_OPCOUNT(cnt, m, n);
        op_band[es->th_id] += cnt;
        op_offpath[es->th_id] += cnt;
    }

    if ( (m-k < band_size) && (tempmm > smallnb) )
    {
        if(DEBUG_INFO) printf("GEMM Recursive: %d %d %d\n", m, n, k);
        subtile_desc_t *small_descA;
        subtile_desc_t *small_descB;
        subtile_desc_t *small_descC;
        parsec_taskpool_t *parsec_dgemm;

        small_descA = subtile_desc_create( descA, m, k,
                                           smallnb, smallnb, 0, 0, tempmm, descA->mb );
        small_descA->mat = A;

        small_descB = subtile_desc_create( descA, n, k,
                                           smallnb, smallnb, 0, 0, descA->mb, descA->mb );
        small_descB->mat = B;

        small_descC = subtile_desc_create( descA, m, n,
                                           smallnb, smallnb, 0, 0, tempmm, descA->mb );
        small_descC->mat = C;

        parsec_dgemm = dplasma_dgemm_New(PlasmaNoTrans, PlasmaTrans,
                                        (double)-1.0,
                                        (parsec_tiled_matrix_dc_t *)small_descA,
                                        (parsec_tiled_matrix_dc_t *)small_descB,
                                        (double) 1.0,
                                        (parsec_tiled_matrix_dc_t *)small_descC);

        parsec_recursivecall(es, (parsec_task_t*)this_task,
                             parsec_dgemm, dplasma_dgemm_Destruct,
                             3, small_descA, small_descB, small_descC );

        return PARSEC_HOOK_RETURN_ASYNC;
    }
    else
        /* Go to CPU sequential kernel */
        return PARSEC_HOOK_RETURN_NEXT;
}
END

BODY
{
    /* Gather rank */
    if( m-n >= band_size && descRank->super.myrank == sym_twoDBC_band_rank_of(&descRank->super, m, n) && 0 == k ) {
        /* New data_copy and allocate memory for descRank(m, n) */
        parsec_data_copy_t *my_data_copy = parsec_data_copy_new(descRank->super.data_of(&descRank->super, m, n), 0);
        my_data_copy->device_private = calloc(4, sizeof(int));

        ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[0] = ((int *)Cr)[0];
        ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[1] = ((int *)Cr)[0];
        ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[2] = ((int *)Cr)[0];
        ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[3] = ((int *)Cr)[0];
    } 

    //printf("enable gemm:%d\n", enable_gemm);
    if(enable_gemm == 0) return PARSEC_HOOK_RETURN_DONE;
    if(DEBUG_INFO) printf("GEMM (%d, %d, %d): k_pre %d, k_next %d\n", m, n, k, k_pre, k_next);

    /** Calls two-step hcore_gemm.
        First step reveals ACTUAL_RANK.
        Second step constructs new CU and CV.
        Provided CU and CV buffers must have at least ACTUAL_RANK number of columns. */
    int call_two_step_hcore_gemm = two_step_hcore_gemm;

    /* No recursive */
    if ( m-k < band_size ) {
        int tempmm = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
        int ldam = BLKLDD( descA, m );
        int ldan = BLKLDD( descA, n );

#if !defined(PARSEC_DRY_RUN)
        CORE_dgemm(PlasmaNoTrans, PlasmaTrans,
                   tempmm, descA->mb, descA->mb,
                   (double)-1.0, A /*A(m, k)*/, ldam,
                                 B /*A(n, k)*/, ldan,
                   (double) 1.0, C /*A(m, n)*/, ldam);
#endif  /* !defined(PARSEC_DRY_RUN) */

    } else if( n-k < band_size && m-n < band_size ) {
        void *p_elem_work_mbr = parsec_private_memory_pop( p_work_mbr );
        int Arank = ((int *)Ar)[0];
        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * Arank * sizeof(double);

#if !defined(PARSEC_DRY_RUN)

        /* tmp_mbr = trans(Av) * trans(B) */
        CORE_dgemm(PlasmaTrans, PlasmaTrans,
                   Arank, descA->mb, descA->mb,
                   (double)1.0, Av /*A(m, k)*/, descA->mb,
                                 B /*A(n, m)*/, descA->mb,
                   (double) 0.0, p_elem_work_mbr /*A(k, n)*/, Arank);

        /* C = C - Au * tmp_mbr */ 
        CORE_dgemm(PlasmaNoTrans, PlasmaNoTrans,
                   descA->mb, descA->mb, Arank,
                   (double)-1.0, Au              /*A(m, k)*/, descA->mb,
                                 p_elem_work_mbr /*A(k, n)*/, Arank,
                   (double) 1.0, C               /*A(m, n)*/, descA->mb);

#endif  /* !defined(PARSEC_DRY_RUN) */

        parsec_private_memory_push( p_work_mbr, p_elem_work_mbr );

    } else if( m-n < band_size ) {
        void *p_elem_work_mbr = parsec_private_memory_pop( p_work_mbr );
        void *p_elem_work_rr = parsec_private_memory_pop( p_work_rr );
        int Arank = ((int *)Ar)[0];
        int Brank = ((int *)Br)[0];

        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * Arank * sizeof(double);

        //void *Bu = (void *)B;
        //void *Bv = (void *)B + descA->mb * Brank * sizeof(double);

#if !defined(PARSEC_DRY_RUN)
        /* tmp_rr = trans(Av) * Bv */
        CORE_dgemm(PlasmaTrans, PlasmaNoTrans,
                   Arank, Brank, descA->mb,
                   (double) 1.0, Av             /*A(k, m)*/, descA->mb,
                                 Bv             /*A(k, n)*/, descA->mb,
                   (double) 0.0, p_elem_work_rr /*A(m, n)*/, Arank);

        if( Arank > Brank ) {
            /* tmp_mbr = Au * tmp_rr */
            CORE_dgemm(PlasmaNoTrans, PlasmaNoTrans,
                       descA->mb, Brank, Arank,
                       (double) 1.0, Au              /*A(m, k)*/, descA->mb,
                                     p_elem_work_rr  /*A(k, n)*/, Arank,
                       (double) 0.0, p_elem_work_mbr /*A(m, n)*/, descA->mb);

            /* C = C - tmp_mbr * trans(Bu) */
            CORE_dgemm(PlasmaNoTrans, PlasmaTrans,
                       descA->mb, descA->mb, Brank,
                       (double)-1.0, p_elem_work_mbr /*A(m, k)*/, descA->mb,
                                     Bu              /*A(n, k)*/, descA->mb,
                       (double) 1.0, C               /*A(m, n)*/, descA->mb);
        } else {
            /* tmp_mbr = tmp_rr * trans(Bu) */
            CORE_dgemm(PlasmaNoTrans, PlasmaTrans,
                       Arank, descA->mb, Brank,
                       (double) 1.0, p_elem_work_rr  /*A(m, k)*/, Arank,
                                     Bu              /*A(n, k)*/, descA->mb,
                       (double) 0.0, p_elem_work_mbr /*A(m, n)*/, Arank);

            /* C = C - Au * tmp_mbr */
            CORE_dgemm(PlasmaNoTrans, PlasmaNoTrans,
                       descA->mb, descA->mb, Arank,
                       (double)-1.0, Au              /*A(m, k)*/, descA->mb,
                                     p_elem_work_mbr /*A(k, n)*/, Arank,
                       (double) 1.0, C               /*A(m, n)*/, descA->mb);
        }

#endif  /* !defined(PARSEC_DRY_RUN) */
        
        parsec_private_memory_push( p_work_mbr, p_elem_work_mbr );
        parsec_private_memory_push( p_work_rr, p_elem_work_rr );

    } else if( n-k < band_size && m-n >= band_size ) {
        int tempmmu = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
        int tempmmv = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
        int ldamu = BLKLDD( descA, m );
        int ldamv = BLKLDD( descA, m );
        int ldanu = BLKLDD( descA, n );
        int ldanv = BLKLDD( descA, n );

        int Arank = ((int*)Ar)[0];
        int Crank_old = ((int*)Cr)[0];

        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * Arank * sizeof(double);// FIXME descA->mb might cause problem for cleanup tiles

        //void *Cu = (void *)C;
        void *Cv = (void *)Cu + descA->mb * Crank_old * sizeof(double);// FIXME descA->mb might cause problem for cleanup tiles

        void *p_elem_work = NULL;
        p_elem_work = parsec_private_memory_pop( p_work );
        int new_Crank = ((int*)Cr)[0];

        double* work_new;
        double* _CU;
        double* _CV;
        int CU_ncols;
        int new_UVrk;
        double* newU;
        int ld_newU;
        double* qrtauA;
        int CV_ncols;
        double* newV;
        int ld_newV;
        double* qrtauB;
        int use_CUV_clone;
        double* CUclone;
        int ld_CUclone;
        double *_CU_save;
        double* CVclone;
        int ld_CVclone;
        double* _CV_save;
        HiCMA_HCORE_dgemm_qr_svd_b_dense( PlasmaNoTrans, PlasmaTrans,
                tempmmv, // ASSUMPTION: For a tile, if nrows<ncols, storage is ncols for both U and V
                tempmmv,
                (double)-1.0,
                Au, Av, Ar, ldamu,
                B, ldamv,
                (double)1.0,
                Cu, Cv, &new_Crank, ldamu,
                rk, storage_maxrank, computation_maxrank, acc, p_elem_work,
                /** parameters that will be passed to HiCMA_HCORE_dgemm_ormqr */
                &work_new,
                &_CU,
                &_CV,
                &CU_ncols,
                &new_UVrk,
                &newU,
                &ld_newU,
                &qrtauA,
                &CV_ncols,
                &newV,
                &ld_newV,
                &qrtauB,
                &use_CUV_clone,
                &CUclone,
                &ld_CUclone,
                &_CU_save,
                &CVclone,
                &ld_CVclone,
                &_CV_save
                    );

        /* If new_UVrk > Crank_old, re-allocate */
        if( new_UVrk > Crank_old && !send_full_tile ) {
            if( DEBUG_INFO ) printf("Reallocate %d %d %d\n", m, n, k);
            free( this_task->data._f_Cu.data_out->device_private ); 
            this_task->data._f_Cu.data_out->device_private = calloc( descA->mb * new_UVrk * 2, sizeof(double) );
            this_task->data._f_Cu.data_out->original->nb_elts = descA->mb * new_UVrk * 2 * sizeof(double);
        }

        /* Address for Cu and Cv to be copied to */
        _CU_save = this_task->data._f_Cu.data_out->device_private;
        _CV_save = this_task->data._f_Cu.data_out->device_private + descA->mb * new_UVrk * sizeof(double);

        HiCMA_HCORE_dgemm_ormqr( PlasmaNoTrans, PlasmaTrans,
                tempmmv, // ASSUMPTION: For a tile, if nrows<ncols, storage is ncols for both U and V
                tempmmv,
                (double)-1.0,
                Au, Av, Ar, ldamu,
                (double)1.0,
                Cu, Cv, &new_Crank, ldamu,
                rk, 2*storage_maxrank, computation_maxrank, acc, work_new,
                /** parameters coming from HiCMA_HCORE_dgemm_qr_svd */
                _CU,
                _CV,
                CU_ncols,
                new_UVrk,
                newU,
                ld_newU,
                qrtauA,
                CV_ncols,
                newV,
                ld_newV,
                qrtauB,
                use_CUV_clone,
                CUclone,
                ld_CUclone,
                _CU_save,
                CVclone,
                ld_CVclone,
                _CV_save
                    );

        ((int*)Cr)[0] = new_Crank;
        parsec_private_memory_push( p_work, p_elem_work );

        /* Operation count */
        int Crank_old__Arank = Crank_old + Arank;
        unsigned long int cnt = 0;

        /// QR([CU AU])
        unsigned long int qraflop = ka_counts('q', tempmmv, Crank_old__Arank, 0, 0);///ASSUMPTION:tempmmv is not totally correct if nrowsC<ncolsC
        unsigned long int qrbflop = ka_counts('q', tempmmv, Crank_old__Arank, 0, 0);
        /// Au * B
        qrbflop += ka_counts('m', Arank, tempmmv, tempmmv, 0);
        int rA_nrows  = tempmmv < Crank_old__Arank ? tempmmv : Crank_old__Arank;
        unsigned long int svdflop = ka_counts('r', Crank_old__Arank, Crank_old__Arank, 2, 0);// trmm is used
        svdflop += ka_counts('s', Crank_old__Arank, 0, 0, 0);
        svdflop += Crank_old__Arank * new_Crank;
        unsigned long int newuflop = ka_counts('o', tempmmv, new_Crank, Crank_old__Arank, 1);
        unsigned long int newvflop = ka_counts('o', new_Crank, tempmmv, Crank_old__Arank, 2);

        cnt = qraflop + qrbflop + svdflop + newuflop + newvflop;
        LOG_OPCOUNT(cnt, m, n);
        op_offband[es->th_id] += cnt;
        op_offpath[es->th_id] += cnt;

    } else {
        int tempmmu = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
        int tempmmv = m == descA->mt-1 ? descA->m - m * descA->mb : descA->mb;
        int ldamu = BLKLDD( descA, m );
        int ldamv = BLKLDD( descA, m );
        int ldanu = BLKLDD( descA, n );
        int ldanv = BLKLDD( descA, n );

        int Arank = ((int*)Ar)[0];
        int Brank = ((int*)Br)[0];
        int Crank_old = ((int*)Cr)[0];

        //void *Au = (void *)A;
        //void *Av = (void *)A + descA->mb * Arank * sizeof(double);// FIXME descA->mb might cause problem for cleanup tiles

        //void *Bu = (void *)B;
        //void *Bv = (void *)B + descA->mb * Brank * sizeof(double); // FIXME descA->mb might cause problem for cleanup tiles

        //void *Cu = (void *)C;
        void *Cv = (void *)Cu + descA->mb * Crank_old * sizeof(double);// FIXME descA->mb might cause problem for cleanup tiles

        void *p_elem_work = NULL;
        p_elem_work = parsec_private_memory_pop( p_work );

#if !defined(PARSEC_DRY_RUN)
	double* work_new;
	double* _CU;
	double* _CV;
	int CU_ncols;
	int new_UVrk;
	double* newU;
	int ld_newU;
	double* qrtauA;
	int CV_ncols;
	double* newV;
	int ld_newV;
	double* qrtauB;
	int use_CUV_clone;
	double* CUclone;
	int ld_CUclone;
	double *_CU_save;
	double* CVclone;
	int ld_CVclone;
	double* _CV_save;
	HiCMA_HCORE_dgemm_qr_svd( PlasmaNoTrans, PlasmaTrans,
			tempmmv, // ASSUMPTION: For a tile, if nrows<ncols, storage is ncols for both U and V
			tempmmv,
			(double)-1.0,
			Au, Av, Ar, ldamu,
			Bu, Bv, Br, ldamv,
			(double)1.0,
			Cu, Cv, Cr, ldamu,
			rk, storage_maxrank, computation_maxrank, acc, p_elem_work,
			/** parameters that will be passed to HiCMA_HCORE_dgemm_ormqr */
			&work_new,
			&_CU,
			&_CV,
			&CU_ncols,
			&new_UVrk,
			&newU,
			&ld_newU,
			&qrtauA,
			&CV_ncols,
			&newV,
			&ld_newV,
			&qrtauB,
			&use_CUV_clone,
			&CUclone,
			&ld_CUclone,
			&_CU_save,
			&CVclone,
			&ld_CVclone,
			&_CV_save
				);

	/* If new_UVrk > Crank_old, re-allocate */
	if( new_UVrk > Crank_old && !send_full_tile ) {
		if( DEBUG_INFO ) printf("\nReallocate %d %d %d\n\n", m, n, k);
		free( this_task->data._f_Cu.data_out->device_private ); 
		this_task->data._f_Cu.data_out->device_private = calloc( descA->mb * new_UVrk * 2, sizeof(double) );
		this_task->data._f_Cu.data_out->original->nb_elts = descA->mb * new_UVrk * 2 * sizeof(double);
	}

	/* Address for Cu and Cv to be copied to */
	_CU_save = this_task->data._f_Cu.data_out->device_private;
	_CV_save = this_task->data._f_Cu.data_out->device_private + descA->mb * new_UVrk * sizeof(double);

	HiCMA_HCORE_dgemm_ormqr( PlasmaNoTrans, PlasmaTrans,
			tempmmv, // ASSUMPTION: For a tile, if nrows<ncols, storage is ncols for both U and V
			tempmmv,
			(double)-1.0,
			Au, Av, Ar, ldamu,
			(double)1.0,
			Cu, Cv, Cr, ldamu,
			rk, storage_maxrank, computation_maxrank, acc, work_new,
			/** parameters coming from HiCMA_HCORE_dgemm_qr_svd */
			_CU,
			_CV,
			CU_ncols,
			new_UVrk,
			newU,
			ld_newU,
			qrtauA,
			CV_ncols,
			newV,
			ld_newV,
			qrtauB,
			use_CUV_clone,
			CUclone,
			ld_CUclone,
			_CU_save,
			CVclone,
			ld_CVclone,
			_CV_save
				);

	Cu = _CU_save;
	Cv = _CV_save;
#endif  /* !defined(PARSEC_DRY_RUN) */

	parsec_private_memory_push( p_work, p_elem_work );
	int Crank_new = ((int*)Cr)[0];

	printlog("HCORE_dgemm( %d, %d, %d )\n\t( %s, %s, %d, %d, %d, %f, A(%d,%d)[%p], %d-%d, A(%d,%d)[%p], %d-%d, %f, A(%d,%d)[%p], %d-%d)\n",
			m, n, k,
			plasma_const( PlasmaNoTrans ),  plasma_const( PlasmaTrans ),
			tempmmu, tempmmv, descA->mb,
			-1.0, m, k, Au, ldamu, ldamv,
			n, k, Bu, ldanu, ldanv,
			1.0, m, n, Cu, ldamu, ldamv);

	if(DEBUG_INFO) printf("GEMM %d %d %d: Crank_old %d, Crank_new %d\n", m, n, k, Crank_old, Crank_new);

	/* Pass Cr value to size */
        if(send_full_tile == 1){
            this_task->locals.size.value = descA->mb * storage_maxrank;
        } else {
            this_task->locals.size.value = descA->mb * ((int *)Cr)[0];
        }
        if(verbose_r) printf("Cr value in DGEMM (%d, %d, %d): %d\n", m, n, k, ((int *)Cr)[0]);
        int Crank_old__Arank = Crank_old + Arank;
        unsigned long int cnt = 0;
        /// QR([CU AU])
        unsigned long int qraflop = ka_counts('q', tempmmv, Crank_old__Arank, 0, 0);///ASSUMPTION:tempmmv is not totally correct if nrowsC<ncolsC
        /// AV*BV^T
        unsigned long int qrbflop = ka_counts('m', Arank, Brank, tempmmv, 0);
        /// (AV*BV^T) * BU^T
        qrbflop += ka_counts('m', Arank, tempmmv, Brank, 0);
        qrbflop += ka_counts('q', tempmmv, Crank_old__Arank, 0, 0);  
        int rA_nrows  = tempmmv < Crank_old__Arank ? tempmmv : Crank_old__Arank;
        unsigned long int svdflop = ka_counts('r', Crank_old__Arank, Crank_old__Arank, 2, 0);// trmm is used
        svdflop += ka_counts('s', Crank_old__Arank, 0, 0, 0);
        svdflop += Crank_old__Arank * Crank_new; 
        unsigned long int newuflop = ka_counts('o', tempmmv, Crank_new, Crank_old__Arank, 1);  
        unsigned long int newvflop = ka_counts('o', Crank_new, tempmmv, Crank_old__Arank, 2); 

        cnt = qraflop + qrbflop + svdflop + newuflop + newvflop;
        LOG_OPCOUNT(cnt, m, n);

        op_offband[es->th_id] += cnt;
        op_offpath[es->th_id] += cnt;
    }

    /* Gather rank */
    if( m-n >= band_size && descRank->super.myrank == sym_twoDBC_band_rank_of(&descRank->super, m, n) ) {
        if( ((int *)Cr)[0] < ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[1] ) 
            ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[1] = ((int *)Cr)[0];
  
        if( ((int *)Cr)[0] > ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[2] ) 
            ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[2] = ((int *)Cr)[0];

        if( descA->mt-3 == k ) 
            ((int *)((descRank->super.data_of(&descRank->super, m, n))->device_copies[0]->device_private))[3] = ((int *)Cr)[0];
    }

}
END
